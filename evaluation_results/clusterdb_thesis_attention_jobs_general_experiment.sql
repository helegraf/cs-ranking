create table jobs_general_experiment
(
    job_id              int4 default nextval('thesis_attention.jobs_general_job_id_seq'::regclass) not null,
    cluster_id          int4,
    resources           json,
    dataset             text,
    dataset_params      json,
    fold_id             int4,
    n_inner_folds       int4,
    learning_problem    text,
    seed                int4,
    learner_name        text,
    learner_params      json,
    learner_fit_params  json,
    use_hp              bool,
    hp_iterations       int4,
    hp_ranges           json,
    hp_fit_params       json,
    duration            text,
    actual_duration     interval(6),
    time_out_eval       text,
    results_table_name  text,
    hash_value          text,
    time_start          timestamp(6),
    time_start_train    timestamp(6),
    time_finished_train timestamp(6),
    time_finished_vis   timestamp(6),
    time_finished       timestamp(6),
    time_updated        timestamp(6),
    error_history       text,
    note                text
);

INSERT INTO thesis_attention.jobs_general_experiment (job_id, cluster_id, resources, dataset, dataset_params, fold_id, n_inner_folds, learning_problem, seed, learner_name, learner_params, learner_fit_params, use_hp, hp_iterations, hp_ranges, hp_fit_params, duration, actual_duration, time_out_eval, results_table_name, hash_value, time_start, time_start_train, time_finished_train, time_finished_vis, time_finished, time_updated, error_history, note) VALUES (26, null, '{"gtx1080": "1", "ncpus": "2", "vmem": "42g", "mem": "16g"}', 'synthetic_or', '{"dataset_type": "tsp", "n_objects": 10, "n_train_instances": 64, "n_test_instances": 64}', 1, 0, 'object_ranking_tsp', 5678, 'set_transformer_ranker', '{"stacking_height": 3, "attention_layer_config": {"SAB": {"mab": {"MAB": {"multi_head": {"MultiHeadAttention": {"num_heads": 1, "attention_config": {"ScaledDotProductAttention": {"weighted": false, "biased": false}}}}}}}}, "num_layers_dense": 2, "num_units_dense": 8, "seed": 10}', '{"epochs": 16, "validation_split": 0.1, "verbose": 0, "callbacks": {"AdvancedTensorBoard": {"num_visualizations_per_epoch": 3, "visualization_frequency": 1, "save_space": true, "save_visualization_data": false, "log_lr": true, "log_gradient_norms": true, "log_dir": "./tensorboard_logs/", "metrics": ["TSPRelativeDifference_requiresX"], "metric_requires_x": [true], "histogram_freq": 8, "batch_size": 8, "write_graph": true, "write_grads": false, "write_images": false, "embeddings_freq": 0, "update_freq": "epoch"}, "CyclicLR": {"base_lr": 2e-06, "max_lr": 1e-05, "step_size": 128, "mode": "triangular2"}}}', false, 0, '{}', '{}', '12h', null, '10m', 'results_general_experiment', 'c2a5b8aaaa6598032e87ce58e881111197fef62d', null, null, null, null, null, null, null, null);
INSERT INTO thesis_attention.jobs_general_experiment (job_id, cluster_id, resources, dataset, dataset_params, fold_id, n_inner_folds, learning_problem, seed, learner_name, learner_params, learner_fit_params, use_hp, hp_iterations, hp_ranges, hp_fit_params, duration, actual_duration, time_out_eval, results_table_name, hash_value, time_start, time_start_train, time_finished_train, time_finished_vis, time_finished, time_updated, error_history, note) VALUES (25, 41, '{"gtx1080": "1", "ncpus": "2", "vmem": "42g", "mem": "16g"}', 'synthetic_or', '{"dataset_type": "tsp", "n_objects": 10, "n_train_instances": 64, "n_test_instances": 64}', 1, 0, 'object_ranking_tsp', 5678, 'feta_ranker', '{"attention_pooling": {"PMA": {"k": 1, "mab": {"MAB": {"multi_head": {"MultiHeadAttention": {"num_heads": 1, "attention_config": {"ScaledDotProductAttention": {"weighted": false, "biased": false}}}}}}}}, "attention_function_preselection": {"ScaledDotProductAttention": {"weighted": false, "biased": false}}, "loss_function": "tsp_probability_matrix_loss", "n_hidden": 2, "n_units": 8, "add_zeroth_order_model": true, "max_number_of_objects": 10, "n_hidden_joint_layers": 3, "n_hidden_joint_units": 3, "activation": "selu", "kernel_initializer": "lecun_normal", "batch_size": 8, "kernel_regularizer": "l2", "kernel_regularizer_params": {"l": 0.01}, "optimizer": "SGD", "optimizer_params": {"lr": 0.0001, "nesterov": "true", "momentum": 0.9}}', '{"epochs": 16, "validation_split": 0.1, "verbose": 0, "callbacks": {"AdvancedTensorBoard": {"num_visualizations_per_epoch": 3, "visualization_frequency": 1, "save_space": true, "log_lr": true, "log_gradient_norms": true, "log_dir": "./tensorboard_logs/", "histogram_freq": 8, "batch_size": 8, "write_graph": false, "write_grads": false, "write_images": false, "embeddings_freq": 0, "update_freq": "epoch"}, "CyclicLR": {"base_lr": 2e-06, "max_lr": 1e-05, "step_size": 128, "mode": "triangular2"}}}', false, 0, '{}', '{}', '12h', null, '10m', 'results_general_experiment', '6c2075d9c14e8a73f089016a7720f745194eb8ae', '2020-05-12 11:11:44.083548', '2020-05-12 11:11:45.008699', null, null, null, '2020-05-12 11:11:45.022778', '__init__() got an unexpected keyword argument ''visualization_frequency'';
''NoneType'' object is not subscriptable;
__init__() got an unexpected keyword argument ''num_visualizations_per_epoch'';
__init__() got an unexpected keyword argument ''num_visualizations_per_epoch''', null);
INSERT INTO thesis_attention.jobs_general_experiment (job_id, cluster_id, resources, dataset, dataset_params, fold_id, n_inner_folds, learning_problem, seed, learner_name, learner_params, learner_fit_params, use_hp, hp_iterations, hp_ranges, hp_fit_params, duration, actual_duration, time_out_eval, results_table_name, hash_value, time_start, time_start_train, time_finished_train, time_finished_vis, time_finished, time_updated, error_history, note) VALUES (28, null, '{"gtx1080": "1", "ncpus": "2", "vmem": "42g", "mem": "16g"}', 'synthetic_or', '{"dataset_type": "tsp", "n_objects": 10, "n_train_instances": 64, "n_test_instances": 64}', 1, 0, 'object_ranking_tsp', 5678, 'set_transformer_ranker', '{"stacking_height": 3, "attention_layer_config": {"SAB": {"mab": {"MAB": {"multi_head": {"MultiHeadAttention": {"num_heads": 1, "attention_config": {"ScaledDotProductAttention": {"weighted": false, "biased": false}}}}}}}}, "num_layers_dense": 2, "num_units_dense": 8, "seed": 10}', '{"epochs": 16, "validation_split": 0.1, "verbose": 0, "callbacks": {"AdvancedTensorBoard": {"num_visualizations_per_epoch": 3, "save_space": true, "log_lr": true, "log_gradient_norms": "global", "log_dir": "./tensorboard_logs/", "histogram_freq": 8, "write_graph": true, "write_grads": false, "write_images": false, "embeddings_freq": 0, "update_freq": "epoch"}, "CyclicLR": {"base_lr": 2e-06, "max_lr": 1e-05, "step_size": 128, "mode": "triangular2"}}}', false, 0, '{}', '{}', '12h', null, '10m', 'results_general_experiment', '2295ffe03561d7bf1edfe844e6069fb89408e2a3', null, null, null, null, null, null, null, null);
INSERT INTO thesis_attention.jobs_general_experiment (job_id, cluster_id, resources, dataset, dataset_params, fold_id, n_inner_folds, learning_problem, seed, learner_name, learner_params, learner_fit_params, use_hp, hp_iterations, hp_ranges, hp_fit_params, duration, actual_duration, time_out_eval, results_table_name, hash_value, time_start, time_start_train, time_finished_train, time_finished_vis, time_finished, time_updated, error_history, note) VALUES (30, 41, '{"gtx1080": "1", "ncpus": "2", "vmem": "42g", "mem": "16g"}', 'synthetic_or', '{"dataset_type": "tsp", "n_objects": 10, "n_train_instances": 64, "n_test_instances": 64}', 1, 0, 'object_ranking_tsp', 5678, 'set_transformer_ranker', '{"stacking_height": 3, "attention_layer_config": {"SAB": {"mab": {"MAB": {"multi_head": {"MultiHeadAttention": {"num_heads": 1, "attention_config": {"ScaledDotProductAttention": {"weighted": false, "biased": false}}}}}}}}, "num_layers_dense": 2, "num_units_dense": 8, "seed": 10}', '{"epochs": 16, "validation_split": 0.1, "verbose": 0, "callbacks": {"AdvancedTensorBoard": {"num_visualizations_per_epoch": 3, "save_space": true, "log_lr": true, "log_gradient_norms": "global", "log_attention": true, "log_dir": "./tensorboard_logs/", "histogram_freq": 8, "write_graph": true, "write_grads": false, "write_images": false, "embeddings_freq": 0, "update_freq": "epoch"}, "CyclicLR": {"base_lr": 2e-06, "max_lr": 1e-05, "step_size": 128, "mode": "triangular2"}}}', false, 0, '{}', '{}', '12h', '0 years 0 mons 0 days 0 hours 1 mins 24.538071 secs', '10m', 'results_general_experiment', '38b0c0d7d6fb7a5b5c1759857dc69b1c9b325afd', '2020-05-12 11:38:37.682392', '2020-05-12 11:38:38.577180', '2020-05-12 11:40:01.874457', '2020-05-12 11:40:01.874743', '2020-05-12 11:40:02.220463', '2020-05-12 11:40:02.219181', null, null);
INSERT INTO thesis_attention.jobs_general_experiment (job_id, cluster_id, resources, dataset, dataset_params, fold_id, n_inner_folds, learning_problem, seed, learner_name, learner_params, learner_fit_params, use_hp, hp_iterations, hp_ranges, hp_fit_params, duration, actual_duration, time_out_eval, results_table_name, hash_value, time_start, time_start_train, time_finished_train, time_finished_vis, time_finished, time_updated, error_history, note) VALUES (27, 41, '{"gtx1080": "1", "ncpus": "2", "vmem": "42g", "mem": "16g"}', 'synthetic_or', '{"dataset_type": "tsp", "n_objects": 10, "n_train_instances": 64, "n_test_instances": 64}', 1, 0, 'object_ranking_tsp', 5678, 'feta_ranker', '{"attention_pooling": {"PMA": {"k": 1, "mab": {"MAB": {"multi_head": {"MultiHeadAttention": {"num_heads": 1, "attention_config": {"ScaledDotProductAttention": {"weighted": false, "biased": false}}}}}}}}, "attention_function_preselection": {"ScaledDotProductAttention": {"weighted": false, "biased": false}}, "loss_function": "tsp_probability_matrix_loss", "n_hidden": 2, "n_units": 8, "add_zeroth_order_model": true, "max_number_of_objects": 10, "n_hidden_joint_layers": 3, "n_hidden_joint_units": 3, "activation": "selu", "kernel_initializer": "lecun_normal", "batch_size": 8, "kernel_regularizer": "l2", "kernel_regularizer_params": {"l": 0.01}, "optimizer": "SGD", "optimizer_params": {"lr": 0.0001, "nesterov": "true", "momentum": 0.9}}', '{"epochs": 16, "validation_split": 0.1, "verbose": 0, "callbacks": {"AdvancedTensorBoard": {"num_visualizations_per_epoch": 3, "save_space": true, "log_lr": true, "log_gradient_norms": "global", "log_dir": "./tensorboard_logs/", "histogram_freq": 8, "write_graph": false, "write_grads": false, "write_images": false, "embeddings_freq": 0, "update_freq": "epoch"}, "CyclicLR": {"base_lr": 2e-06, "max_lr": 1e-05, "step_size": 128, "mode": "triangular2"}}}', false, 0, '{}', '{}', '12h', '0 years 0 mons 0 days 0 hours -1 mins -54.470569 secs', '10m', 'results_general_experiment', 'fed05e1b1a1660e4b7265acbdaab01f3097a61f1', '2020-05-12 11:27:54.450058', '2020-05-12 11:27:55.353169', '2020-05-12 11:30:09.365449', '2020-05-12 11:30:09.366027', '2020-05-12 11:25:59.979489', '2020-05-12 11:30:09.605724', 'FEHLER:  doppelter Schlüsselwert verletzt Unique-Constraint »results_general_experiment_pkey«
DETAIL:  Schlüssel »(job_id, train_test)=(27, ''test'')« existiert bereits.
;
''AdvancedTensorBoard'' object has no attribute ''train_end_time'';
''NoneType'' object is not subscriptable;
__init__() got an unexpected keyword argument ''x''', null);
INSERT INTO thesis_attention.jobs_general_experiment (job_id, cluster_id, resources, dataset, dataset_params, fold_id, n_inner_folds, learning_problem, seed, learner_name, learner_params, learner_fit_params, use_hp, hp_iterations, hp_ranges, hp_fit_params, duration, actual_duration, time_out_eval, results_table_name, hash_value, time_start, time_start_train, time_finished_train, time_finished_vis, time_finished, time_updated, error_history, note) VALUES (29, 41, '{"gtx1080": "1", "ncpus": "2", "vmem": "42g", "mem": "16g"}', 'synthetic_or', '{"dataset_type": "tsp", "n_objects": 10, "n_train_instances": 64, "n_test_instances": 64}', 1, 0, 'object_ranking_tsp', 5678, 'feta_ranker', '{"attention_pooling": {"PMA": {"k": 1, "mab": {"MAB": {"multi_head": {"MultiHeadAttention": {"num_heads": 1, "attention_config": {"ScaledDotProductAttention": {"weighted": false, "biased": false}}}}}}}}, "attention_function_preselection": {"ScaledDotProductAttention": {"weighted": false, "biased": false}}, "loss_function": "tsp_probability_matrix_loss", "n_hidden": 2, "n_units": 8, "add_zeroth_order_model": true, "max_number_of_objects": 10, "n_hidden_joint_layers": 3, "n_hidden_joint_units": 3, "activation": "selu", "kernel_initializer": "lecun_normal", "batch_size": 8, "kernel_regularizer": "l2", "kernel_regularizer_params": {"l": 0.01}, "optimizer": "SGD", "optimizer_params": {"lr": 0.0001, "nesterov": "true", "momentum": 0.9}}', '{"epochs": 16, "validation_split": 0.1, "verbose": 0, "callbacks": {"AdvancedTensorBoard": {"num_visualizations_per_epoch": 3, "save_space": true, "log_lr": true, "log_gradient_norms": "global", "log_attention": true, "log_dir": "./tensorboard_logs/", "histogram_freq": 8, "write_graph": false, "write_grads": false, "write_images": false, "embeddings_freq": 0, "update_freq": "epoch"}, "CyclicLR": {"base_lr": 2e-06, "max_lr": 1e-05, "step_size": 128, "mode": "triangular2"}}}', false, 0, '{}', '{}', '12h', '0 years 0 mons 0 days 0 hours 2 mins 10.547865 secs', '10m', 'results_general_experiment', '124bdf48c055342e7580a99bfd20928586c63e21', '2020-05-12 11:32:37.007508', '2020-05-12 11:32:37.895704', '2020-05-12 11:34:47.093937', '2020-05-12 11:34:47.094425', '2020-05-12 11:34:47.555373', '2020-05-12 11:34:47.554347', null, null);