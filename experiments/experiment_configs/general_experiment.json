{
  "resources": {
    "gtx1080": "1",
    "ncpus": "2",
    "vmem": "42g",
    "mem": "16g"
  },
  "dataset_configs": [
    {
      "dataset": "synthetic_or",
      "dataset_params": {
        "dataset_type": "tsp",
        "n_objects": 10,
        "n_train_instances": 64,
        "n_test_instances": 64
      }
    }
  ],
  "folds": [
    {
      "fold_id": 1,
      "n_inner_folds": 0
    }
  ],
  "learning_problem": "object_ranking_tsp",
  "seeds": [
    {
      "seed": 5678
    }
  ],
  "learners": [
    {
      "learner_name": "feta_ranker",
      "learner_params": {
        "attention_pooling": {"PMA": {"k": 1, "mab": {"MAB": {"multi_head": {
        "MultiHeadAttention": {"num_heads": 1, "attention_config": {"ScaledDotProductAttention":
                                                                 {"weighted": false, "biased": false}}}}}}}},
        "attention_function_preselection": {
          "ScaledDotProductAttention":
          {"weighted": false, "biased": false}
        },
        "loss_function" :  "tsp_probability_matrix_loss",
        "n_hidden":2,
        "n_units":8,
        "add_zeroth_order_model":true,
        "max_number_of_objects":10,
        "n_hidden_joint_layers":3,
        "n_hidden_joint_units":3,
        "activation": "selu",
        "kernel_initializer": "lecun_normal",
        "batch_size": 8,
        "kernel_regularizer": "l2",
        "kernel_regularizer_params": {
          "l": 0.01
        },
        "optimizer": "SGD",
        "optimizer_params": {
          "lr": 1e-4,
          "nesterov": "true",
          "momentum": 0.9
        }
      },
      "learner_fit_params": {
        "epochs": 16,
        "validation_split": 0.1,
        "verbose": 0,
        "callbacks": {
            "AdvancedTensorBoard": {
            "num_visualizations_per_epoch": 3,
            "save_space": true,
            "log_lr": true,
            "log_gradient_norms": "global",
            "log_attention": true,
            "log_dir": "./tensorboard_logs/",
            "histogram_freq": 1,
            "write_graph": false,
            "write_grads": false,
            "write_images": false,
            "embeddings_freq": 0,
            "update_freq": "epoch"
          },
          "CyclicLR": {
            "base_lr": 0.000002,
            "max_lr": 0.00001,
            "step_size": 128,
            "mode": "triangular2"
          }
        }
      }
    },
        {
      "learner_name": "set_transformer_ranker",
      "learner_params": {
        "stacking_height":3,
        "attention_layer_config": {"SAB": {"mab": {"MAB": {"multi_head": {
        "MultiHeadAttention": {"num_heads": 1, "attention_config": {"ScaledDotProductAttention":
                                                                 {"weighted": false, "biased": false}}}}}}}},
        "num_layers_dense":2,
        "num_units_dense":8,
        "seed":10
      },
      "learner_fit_params": {
        "epochs": 16,
        "validation_split": 0.1,
        "verbose": 0,
        "callbacks": {
            "AdvancedTensorBoard": {
            "num_visualizations_per_epoch": 3,
            "save_space": true,
            "log_lr": true,
            "log_gradient_norms": "global",
            "log_attention": true,
            "log_dir": "./tensorboard_logs/",
            "histogram_freq": 1,
            "write_graph": false,
            "write_grads": false,
            "write_images": false,
            "embeddings_freq": 0,
            "update_freq": "epoch"
          },
          "CyclicLR": {
            "base_lr": 0.000002,
            "max_lr": 0.00001,
            "step_size": 128,
            "mode": "triangular2"
          }
        }
      }
    }
  ],
  "optimizers": [
    {
      "use_hp": "False",
      "hp_iterations": 0,
      "hp_ranges": {},
      "hp_fit_params": {}
    }
  ],
  "timings": [
    {
      "duration": "12h",
      "time_out_eval": "10m"
    }
  ],
  "results_table_name": "results_general_experiment"
}